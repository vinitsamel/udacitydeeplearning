{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 1:\n",
      "Image - Min Value: 5 Max Value: 254\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 9 Name: truck\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHURJREFUeJzt3duP3Pd5HvDvzOzskXskuTyLpCiSli3ZVnyo7bhxgbRx\n06ZIi7RFe5Or9qpAL/rv9K7oRXvRIg0cBInTpIlTxzHi2JYlS6IOlEhJPJPLPc3Ozs5MbwP06n27\nqYEXn8/9g3d3dmae/V09nel02gCAmrq/6B8AAPjbo+gBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCY\nogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFDbzi/4B/rb8x9/9o2km\n9/HbPwpnHt1+K3Oqjcfxl//MC59J3Xrh2sup3PrZF8KZ+YXc2+rWm98PZz567/XUrdHObirXS/zN\nVtZXU7dm5hfDma/+8q+kbr10I/6+Onj+NHXrzTd+nMpNJofhzOHoIHXr52/+LJzZ3nqcujU8HKZy\no8NeOPP0yX7q1u5+/HU8Gud+r9OnN1K59Y0T4cx4upO6dTSKZw4GqUpqv/Pf/6CTCv4NnugBoDBF\nDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKK7tet/0s\nt6x1ci2+nDQ9fSZ1azqzEs6ce+HF1K3xJDG31FrrTuJrV5P9o9Stg2dPwpnpILdOduHUZir3wqWX\nwplLL11O3Tp/4WI4s7mZey/2+3PhzNFafF2vtdYuXTybyh0dxdfrDg4GqVtbz+Lrho8f575zZmbn\nU7nWia/XrZ+M/51ba21+Kf46Pt9+lro1N5+rpck0/r3Tn8m9HtvPt8KZw2Fuve44eKIHgMIUPQAU\npugBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIWVHbVpo9yIy+Ewntvf\nj49ttNbalRsXwpndvb3UrcNRbvxl49RqODPTz/3/eP36jXDmG1/7curWhTPxwZjWWltdPR3OjGbG\nqVuL8/HBjZnkbkbnKD4IMtiLD7+01tow+dlcXIiP6Kyv5caLrr342XDmrbfeSd1qndzrMRzGB6dW\nV9ZTt/qz8czz7QepW9OW+z6dTOJv/mfPct+ng/1hODP9xW3aeKIHgMoUPQAUpugBoDBFDwCFKXoA\nKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAorOx63dHBIJXrHMWXxuZmF1K3nj9+\nHM6cPJtbXXvhcy+lcpuXzocz/czUVWutHcVXvEZHuVW+t+89SeX2P3gUzoy6uTWud37203DmKy/H\nV9daa+1XvvqVcGaanOPa3n6eyt356NNwZrY/n7o1O7sSzpw6HV+jbK21O3ffTeVm5+NrfruD3Frb\n9nb8u2qm30ndWlmJ/16ttTYYxNf8xvHRxtZaa0dHk3Bmbi75vXgMPNEDQGGKHgAKU/QAUJiiB4DC\nFD0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMLKjtoM93PjDScW4iMYKxunU7d+6Qtf\nDGcuvXg9dWvnKLfe8M4Hd8OZ7f34uERrre1ubYUzT7Zy4zT37j9L5VZWE3/r7jB16zv/9b+FM/1/\nmfvf/Vtf/2b8Vj8+QtRaa2fPxoeSWmutTePDKlvPdlKn/vrHr4czM/251K2l5fiATmutHY3jo0KH\nu/HPWGut9RJvq9OnN1K3xuPcCNSTp/H3R7flBnRmZuLVuba2mrp1HDzRA0Bhih4AClP0AFCYogeA\nwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFFZ2vW5urp/KjXrL4cxg4UTq\n1u3tQTjzkz//YerW0ye7qdwnnz4IZ/q9TupWvzsJZ4ZHuaWrg4Nc7tzp+Efm4f2PUrdW5mbDmZ2t\n7dStW7dvhzPnzp1K3er3c1875y6dDWfOJzKttXbnfny18Z2fxTOttbZ5Lrd++eGd+FpbG8U/Y621\nNjmM58Yz49St+dncCuDcTPw7f3CQ+xlXVuKLgzMzud/rOHiiB4DCFD0AFKboAaAwRQ8AhSl6AChM\n0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFKXoAKKzset3i4plU7uHWUTjz3t3catXP33wj\nnOkml7/Gw1EqN9jZC2d6iRW61lobDOPLa1s7ubW2nb3cmt+HH78VziwtxBcRW2vt5rWb8VByze9/\nf+9/hTOXr15N3bpx80Yqd/LkajgzN5/7vKyuxJfGukfPU7f2hrnnrcH+MJ7Z2kndGo8Pwpn5hdyC\n6O527mdcWY4vys3N91K3Dg/j36f7+/upW8fBEz0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQ\nmKIHgMIUPQAUpugBoDBFDwCFKXoAKKzsqM3axqlU7r27t8KZex/eTt1a7MdHKZ7vPUvd2t1+mMp1\nJvGBmq2d3GDM1iA+nDEzlxvOOHVmM5VbWI4Pq1y48oXUrUuJwY3bP/2L1K1eJz6GMxqPU7cePX6S\nyr366svhzEvXX0zdunTudDhz4muvpW69/vadVG54MB/P9HODU5MWH4yZTOMDYa21dv/+p6nc7Fx8\niGh1Pfc90Fp87GswGCRv/b/zRA8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCF\nKXoAKEzRA0Bhih4AClP0AFBY2fW699//YSr39vvvhTOf3ns/dWu8E19AWl5dSt26ef1KKvfKy6+E\nM/ce5VaaPnoUfz1Onz2TunX52tVUbvlkfO3qwbP479Vaa9PH8VXEOx/lltAebcUX5V7+bOpU+wc3\n4it0rbW2txt/X01yA3ttehhf83vzB7nlwOs3v5jKnbmwFs784Id/lrp1/8F2ODMa5dbrDgbx1761\n1p492wlnFk7EX8PWWptM4yuAe/u574Hj4IkeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFKXoAKEzR\nA0Bhih4AClP0AFCYogeAwhQ9ABRWdtTmB3/23VRu5szNcObay6+mbi0cxocRXv7s9dStmzcupnLj\ng144M+3mRm322uNwZqY/n7rV6+XGLEZHc+HM3s7T1K3Vw/goyNF4mrp15+GzcGb+xCepW6sr66nc\ni9euhDPT5LPMYGs/nHn7L3+SujUdxL8HWmvtlW//w3Dm1c+/mLo1+Kv4qM37732YurW4eCKVW107\nmUjlVo+2t+Ofl+Ew/p46Lp7oAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBF\nDwCFKXoAKEzRA0Bhih4ACiu7XvfwbnwJrbXWXvvCPw5n5uZOp25txIfh2rnzK6lbT7d2Urm778WX\n1w4n8YW31lrrduJLUr2Z3PLXeDpM5dpR/CMzHubW/Kbj+O92YvVU6taT3b1wpju7lLo1meYW9lpL\n5HJvj3ZiPv45u3L+UurWfC/3enTbbjjz6itXU7fW1uJrj787+MPUrfv34stwrbV2YfN8ODPuHKRu\n9fvx74Ht7fgC4HHxRA8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFKXoAKEzR\nA0Bhih4AClP0AFBY2fW6xRMbqVw/MSS1tfUwdWtuI74ItX+Um+M6yI00tYX15XBmbtLJHTuIr9dN\nk+/gg9F+Kje/ED/Y7Rymbk268VsnTsYXvFprbXYaXynsLaynbk1nE7ONrbVJJ/4364xzC3vdXvy1\n7y/Npm4tnMjljobxRconnzxI3Tq5FF/o/M1/9O3Urb/66Yep3O4g/jk7GD5K3RoO4ouUa8vx7/vj\n4okeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABRWdtTm\n3AtXU7lON/6/z8HBdurWg+34yz+7dip1a3SUG87o9PvhzGB3N3VrNI2/9jMzc6lbR71cbnFlJZzZ\nPLmVujV9Gh/OOBwdpW51JvHXfmFhIXWrm9u0aZNp/Hcbj+NDSa211u3Hf8hpL/fctLsXH6dprbXO\nJD5wNZf4fmutte1H8TGchcXcsNivfP3zqdw7738Uzrzx8/upW7vbe+HMbH8+des4eKIHgMIUPQAU\npugBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAorOx63bSTm8ga\nJda/9ndy61NzifWvne2nqVuHB8NUbn87/rv1O6lTbXkpvih3ej23kLWysZTKnV6L/83GM6upW4O5\n+Hvx6eXzqVvD8b14aLSfujU+OkzlJpP4G2vcjS+8tdZaJ7Fet7axnro1GSdfx8R31epqbnFwtjMN\nZ7Z2kquNo9z65RdfPhvOrC3nViy/850/DGcePXicunUcPNEDQGGKHgAKU/QAUJiiB4DCFD0AFKbo\nAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMLKjtq05HDGzCSeW51PnWqXVuMjHZ95cS1168R8\nbsyi14n/L7i3nRuzONh/Hs4sLI1St25ez43hXLp8MZzp9i+nbu1uxV/HS+fOpW7dvP0wnFnZyL3x\nN9ZXUrmZmdlwZhLfYmmttTZNbGLNLy2mbh0dxMdpWmutm/jd+t3cs91Bi49inTx1InVrdz838rO3\ndT+cuXD6dOrWP/0nvxbO/M7v/VHq1nHwRA8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugB\noDBFDwCFKXoAKEzRA0Bhih4AClP0AFBY2fW6b339S6nci5/9Qjjz6SefpG5dOB9fULtx/Vrq1tnT\nm6lcbxpf2NvZya3XDUfx1apON/7ztdbaiaWlXO5EfLGtN5tbDuwnlhQHe49St37plfjC3pUbV1K3\nRpPc4uA08VxyNMktw0178fdVr5/7Oh0d5Cb2JqP479adyT3bdeYTn7PkreEo9/6Y6fXDmfFh7rvq\ndGKZ75t/9yupW8fBEz0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBF\nDwCFKXoAKKzsqM2XPv+ZVO5zr8VHbQav5IZmllZXwplJ6lJr005u/KWbGIrYWDqbujVN/NuZ/U91\nMsm9kkeJIZGWHOkYDgfhzLWXXkjdWpiNj/wM9p6nbk27ya+dTjw37SQHY6bx3Dj5GZtMcj/j4SD+\n/hhPcmNO3Zn479ZNfjp3nsTHrVpr7aPbd8OZX/7ma6lb+6OdcGYxMwx0TDzRA0Bhih4AClP0AFCY\nogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFFZ2vW5hKbfSdGJ+LpxZ\nWky+jDO9cCQ5dNU62fW6RG4yzS3DTUbxXGZlrLXWOt3c/7hHif3AbnK0atqJ/4wn1jZSt47G8d9r\nPIm/f1trrU1yL8i0jcOZbvbFH8dz45n40mNrrU1b8kN9dBiOdCbx17C11uYSf+v+OPcZWzrIva+m\nD+Jrfo8+eJC6dfHmxXDmcXc3des4eKIHgMIUPQAUpugBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCY\nogeAwhQ9ABSm6AGgMEUPAIUpegAorOx63fJqbsVr2osvUO0P4ytSrbU2HQ7DmWHy1t7uXip3OIrf\nGw5HqVtHR/EFtdEod2uU+L1aa21/fz+e2dtJ3TqaxF+P5Y3V1K3l1bVwZm35VOrW/OxsKjeeJP5m\nnaPUrW6L55aX51O3njzMvRcPBvE1tMlkPXWr0+J/s8k4/v3WWmsry/EF0dZau/zCmXBmsJ/7XpxO\n4u+P1eXcoupx8EQPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhSl6AChM0QNA\nYYoeAAorO2rzO7/7+6ncuP+9cObZswepW7vPH4cz3WnqVHoM58GD+O82nuR+yI3Tm+HM+qmTqVtz\nvdxbf+/pVjhz6923Ure2d+OjJZeuXk7d6vXjY04ry7nX/urVF1K5i5fOxm+9eCF1a2OuE84sz8df\nw9Zam6yupHKt1wtHRuPcyE9vJv5M2Eu8hq21duZKcixpJT6GM5qOU7d6iV2mjY3k3/kYeKIHgMIU\nPQAUpugBoDBFDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAorOx63Xf/\n5Pup3NrFm+HMdBxfGWuttR9//0/CmcsXL6ZunTqZWxr75OP74czRJLcItbixFs4cdiepWw8+vpvK\n/epXvx7OfPHzn0vd2h8ehDPdfu4jffvOR+HMrXffT9362Rs/TuXWVk+EM7/1z/9Z6tYvf+5GODM7\nzT03XTx3KZU7TKzXdbq5RbnJNL5IOWq574HuTC43tzYfzix0c3+zSS++BprbNjwenugBoDBFDwCF\nKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGFlR23+xb/+7VRubvN6\nOLO/Ex9+aa21d3/203Dm3NncAEY3Od6wML8SzhxOBqlbN16Jv/br5zZTt/ZPradyv/Hrfz+cWVxe\nSN3aS4zaTHKbJe1oGh8HOjiK/3yttfbw4dNU7qPbn4Yzi4vx929rrd3/+Ek48+Gb76ZudQ9yr+MH\n9x+GM1/9tS+nbl2+cj6cGY2PUre687OpXOvHx3A6k9zP2DrxW7Od3ADXcfBEDwCFKXoAKEzRA0Bh\nih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUFjZ9bq52dz/MLfefiOc\n2X6eW6+bTqfhzOjwMHVrd3cvlet04nNo83P91K3R/k448/xR/DVsrbUHd+6mcr//B78fzjzbif9e\nrbX2fPd5OLO8kltrW13fCGeWVuZStz7+OL5C11prm6cuhDPzK7l1w+/9Xvzv/PTd11O3xoejVO69\n+w/CmY/3cu/F6y/HlyVXVxZTt1bXV1O5hcX5+K2l3HdVf74Xziwu5j4vx8ETPQAUpugBoDBFDwCF\nKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGFl1+t2nuQW5f74f/xe\nOHP3/sepW93RIJx5/fXt1K2WWKFrrbWjo6PErUnq1ne/88fhzGw/twj1xdd+KZU7nF0OZ7aH+6lb\nH9x5GM48efJW6tbhQfxv9un9D1O3bn+Y+xm//NqXwpl//+/+Q+rWD3/wF+HM0fMnqVvbw2EqN2jx\n5cYP/iq32vi9H90LZ5Zmcqt8/dn4MlxrrfXm4t8Fy8n1uouXr4Qzv/lb/yp1K/6u/795ogeAwhQ9\nABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhZUdtTl35lwqd/3K\n1XBm2nIjLjPdeK6XHKfp9nL/000n8eGM2fml1K3Wnw9Hzp+/kDr197797VRueXExnFmdX0/d+vkb\nPw1nbr33furW2QtXwpmDae491VuIv4attfbGrbfDmZ/fupW6tXjl5XDm009zf+f1tVxuc3Y2nFk8\nsZC69fT+R+HMk0/eS9169PhBKncwjn9XjSa579N7W/Hq/Mav5m4dB0/0AFCYogeAwhQ9ABSm6AGg\nMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhZVdr3v66Gkq97W/841w5hvf\n+lbq1txcL5yZSa7Qdbu53GSaWNhr8d+rtdZGh+NwZnC4n7r15OPbqdzTg1E88zj3XvwgsUT36cP7\nqVsnNs/HQ3PxtcHWWuvM5tbrDo+G4cx3//TPU7cuX3s1nLm0kVtSnO/mvoYX+3PhzPBgJ3Xrg+03\nw5kTyyupW+PpUSp3/9luOHPq1JXUrf1R/Hvxj//0h6lb/+bf/nYq9zd5ogeAwhQ9ABSm6AGgMEUP\nAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhZUdtVlajA8+tNbak+2DcObHr/8o\ndWtzcz2cObN5KnVrNIqPsbTW2rNnW/HQQfw1bK21mUn8Z7xwNTHG0lq7tL6cyn1y6144s7cbH2Np\nrbXNM2fDmcWTa6lbvfn4AMn+IPd3PnfuhVTu/qcfhzOPnzxP3Tp3fi+c6UynqVu7w9xns83Ev+NG\nk/hwVGutzS0sxTOdTurW4ZNHqVzr9sORMxeupE4dDg/DmeTb41h4ogeAwhQ9ABSm6AGgMEUPAIUp\negAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhSl6ACis7HrdXH+Syg0P4mtt3//+/0zd\nmo7i618riwupW6PRUSp3MBiEMzPJ/x8vX7kUzrzytc+mbl17Ibd6t3U3vqB2/9nj1K3Zhfg62bWT\n8cW71lp79Gg3nHn15iupW5979WYq91/+838KZ2babOrWaC/+2Tw8zK35TY9yi3JtPv6Z7s3lVj2v\nXH0xnHl4953UrdbtpWILS/Hf7eWXb6RuHezHPy+Xzm2mbh0HT/QAUJiiB4DCFD0AFKboAaAwRQ8A\nhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFlV2v2x/s54Ld+P8+3/7130idmhzu\nhTO95ArdZJxb85v24ktSvZncYtj80mI4c38rvq7XWms7W7dSuaeD+OvfmZ9P3XrnJx+EM0/+4lHq\n1otX44tyX3npeurW4SC38rYwG18nm45GqVv7iZ+x28t9nU46qVgbTOKf6Zlx7vvj8sX4et3B7pPU\nrc+uLKVyP/zRj8OZTz/KLewN9uLf3dP9Z6lbx8ETPQAUpugBoDBFDwCFKXoAKEzRA0Bhih4AClP0\nAFCYogeAwhQ9ABSm6AGgMEUPAIUpegAorOyozdKJ3LDK6jSeWT59I3VrOByGM/PJ/81mO7nXY7qw\nEM7MLeZuTQ52w5mdne3Urd7iSiq3eW0tnLm2+Dh1693b78dDnfgIUWut9RfjgzGf3LuTunXy1Pr/\nt9zhID4+0lprw+HzcGZvLzfWM9yPv+9ba200jA93zczHh6Naa+3M+dPhzEf3HqRuPbiTeN+31g52\n43+z99/8SerWyZPx12O6vpG6dRw80QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCFKXoAKEzR\nA0Bhih4AClP0AFCYogeAwhQ9ABRWdr1uf+dWLjiJ/+/T75xInXrwIL629O7PP0zdmp+Jr9C11trs\nanyt7dRmbp3s/KnVcGamm/tf9eTqyVRuPIlnDgbPUrc2N+MLexfO5xay7t2/H87cuvVW6taVw6up\nXGbtcWcn/hlrrbX9/fjy2vbz3JJidr1ufDgIZ3pzS6lbb75xKpw5HB6mbm1unknlLnz+lfit07lb\np06fDWfmk6/9cfBEDwCFKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNED\nQGGKHgAKKztqMzk8SOW6if99Zka91K2Vfnwh5Uc/+NPUrfsPHqdynf5cOPPVr34pdeubX/9yOPP8\neW605PW//stUbu8g/r66dedu6tYHH34Yzgz291O3ptNOODO/cjp1a3t7J5XbeRZ/D+9t5waF4q9G\nazO9TKq11eXFVO781fg40PrJc6lbm+fjIy7nX3s1dWtjJTf+MtuLfw/3EpnWWmudRG76i3uu9kQP\nAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DCFD0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQWGc6\nnf6ifwYA4G+JJ3oAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAK\nU/QAUJiiB4DCFD0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAUpugBoDBFDwCF\nKXoAKEzRA0Bhih4AClP0AFCYogeAwhQ9ABSm6AGgMEUPAIUpegAoTNEDQGGKHgAKU/QAUJiiB4DC\nFD0AFKboAaAwRQ8AhSl6AChM0QNAYYoeAApT9ABQmKIHgMIUPQAU9n8AcDj6JmppbZYAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113969438>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 1\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # Reference : Intro to Tensor Flow -  Min-Max scaling for grayscale image data\n",
    "    a = 0\n",
    "    b = 1\n",
    "    grayscale_min = 0\n",
    "    grayscale_max = 255\n",
    "    return a + ( ( (x - grayscale_min)*(b - a) )/( grayscale_max - grayscale_min ) )\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # Reference: Intro to tensor flow - One Hot Encoding\n",
    "    # print (x)\n",
    "    # Create the encoder\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    # Here the encoder finds the classes and assigns one-hot vectors \n",
    "    lb.fit([0,1,2,3,4,5,6,7,8,9])\n",
    "    # And finally, transform the labels into one-hot encoded vectors\n",
    "    return lb.transform(x)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return  tf.placeholder(tf.float32, [None, image_shape[0],image_shape[1],image_shape[2]] , name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return  tf.placeholder(tf.float32, [None, n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvMax In (?, 32, 32, 5)\n",
      "ConvMax Out (?, 4, 4, 10)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print (\"ConvMax In\", x_tensor.get_shape())\n",
    "    x_depth = x_tensor.get_shape().as_list()[-1]\n",
    "    weight= tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], x_depth, conv_num_outputs],stddev=0.1))\n",
    "    bias = tf.Variable(tf.random_normal([conv_num_outputs]))\n",
    "    conv = tf.nn.conv2d(x_tensor, weight, [1, conv_strides[0], conv_strides[1], 1], 'SAME')\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    conv = tf.nn.relu(conv)\n",
    "    conv = tf.nn.max_pool(conv,[1, pool_ksize[0], pool_ksize[1], 1],[1, pool_strides[0], pool_strides[1], 1],'SAME')\n",
    "    print (\"ConvMax Out\", conv.get_shape())\n",
    "    return conv \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten In [None, 10, 30, 6]\n",
      "Flatten Out (?, 1800)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    print (\"Flatten In\", x_shape)\n",
    "    batch_size = x_shape[0] if x_shape[0] != None else -1\n",
    "    flattened_image_size = 1\n",
    "    for i in range(1, len(x_shape)):\n",
    "        flattened_image_size = flattened_image_size * x_shape[i]\n",
    "    ret = tf.reshape(x_tensor, (batch_size, flattened_image_size))\n",
    "    print (\"Flatten Out\", ret.get_shape())\n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConn In [None, 128]\n",
      "FullyConn Out (?, 40)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    print (\"FullyConn In\", x_shape)\n",
    "    weights = tf.Variable(tf.truncated_normal([x_shape[-1], num_outputs], stddev = 0.1))\n",
    "    bias    = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    ret_tf  = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    ret_tf  = tf.nn.relu(ret_tf)\n",
    "    print (\"FullyConn Out\", ret_tf.get_shape())\n",
    "    return ret_tf\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output In [None, 128]\n",
      "Output Out (?, 40)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_shape = x_tensor.get_shape().as_list()\n",
    "    print (\"Output In\", x_shape)\n",
    "    weights = tf.Variable(tf.truncated_normal([x_shape[-1], num_outputs], stddev = 0.1))\n",
    "    bias    = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    ret_tf  = tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    #ret_tf  = tf.nn.relu(ret_tf)\n",
    "    print (\"Output Out\", ret_tf.get_shape())\n",
    "    return ret_tf\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvMax In (?, 32, 32, 3)\n",
      "ConvMax Out (?, 16, 16, 64)\n",
      "Flatten In [None, 16, 16, 64]\n",
      "Flatten Out (?, 16384)\n",
      "FullyConn In [None, 16384]\n",
      "FullyConn Out (?, 600)\n",
      "FullyConn In [None, 600]\n",
      "FullyConn Out (?, 80)\n",
      "Output In [None, 80]\n",
      "Output Out (?, 10)\n",
      "ConvMax In (?, 32, 32, 3)\n",
      "ConvMax Out (?, 16, 16, 64)\n",
      "Flatten In [None, 16, 16, 64]\n",
      "Flatten Out (?, 16384)\n",
      "FullyConn In [None, 16384]\n",
      "FullyConn Out (?, 600)\n",
      "FullyConn In [None, 600]\n",
      "FullyConn Out (?, 80)\n",
      "Output In [None, 80]\n",
      "Output Out (?, 10)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    convmax = conv2d_maxpool(x, 64, (8,8), (2,2), (4,4), (1,1))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat = flatten(convmax)\n",
    "    \n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fullyconn = fully_conn(flat, 600)\n",
    "    drop = tf.nn.dropout(fullyconn, keep_prob)\n",
    "    fullyconn = fully_conn(drop, 80)\n",
    "    drop = tf.nn.dropout(fullyconn, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    return output(drop, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_accuracy = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss = {0} and Validation Accuracy = {1}'.format(loss, valid_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 45\n",
    "batch_size = 512\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "45\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss = 2.714409112930298 and Validation Accuracy = 0.0997999981045723\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss = 2.702918529510498 and Validation Accuracy = 0.0997999981045723\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss = 2.68631649017334 and Validation Accuracy = 0.1005999967455864\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss = 2.653907537460327 and Validation Accuracy = 0.10899999737739563\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss = 2.4161806106567383 and Validation Accuracy = 0.14980000257492065\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss = 2.3009116649627686 and Validation Accuracy = 0.15919999778270721\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss = 2.2251298427581787 and Validation Accuracy = 0.21979999542236328\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss = 2.1258487701416016 and Validation Accuracy = 0.2280000001192093\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss = 2.033878803253174 and Validation Accuracy = 0.27379998564720154\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss = 2.0220019817352295 and Validation Accuracy = 0.27619999647140503\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss = 1.9375813007354736 and Validation Accuracy = 0.31200000643730164\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss = 1.9159280061721802 and Validation Accuracy = 0.3147999942302704\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss = 1.8547120094299316 and Validation Accuracy = 0.3353999853134155\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss = 1.865557312965393 and Validation Accuracy = 0.3474000096321106\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss = 1.7672871351242065 and Validation Accuracy = 0.36800000071525574\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss = 1.721395492553711 and Validation Accuracy = 0.387800008058548\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss = 1.741246223449707 and Validation Accuracy = 0.3831999897956848\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss = 1.6401211023330688 and Validation Accuracy = 0.41260001063346863\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss = 1.6685912609100342 and Validation Accuracy = 0.4092000126838684\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss = 1.5938656330108643 and Validation Accuracy = 0.41280001401901245\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss = 1.528032898902893 and Validation Accuracy = 0.43799999356269836\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss = 1.5460964441299438 and Validation Accuracy = 0.4334000051021576\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss = 1.4909207820892334 and Validation Accuracy = 0.44839999079704285\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss = 1.4751423597335815 and Validation Accuracy = 0.4505999982357025\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss = 1.4314144849777222 and Validation Accuracy = 0.46639999747276306\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss = 1.4116885662078857 and Validation Accuracy = 0.4580000042915344\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss = 1.3772817850112915 and Validation Accuracy = 0.4715999960899353\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss = 1.325887680053711 and Validation Accuracy = 0.4758000075817108\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss = 1.409541368484497 and Validation Accuracy = 0.4620000123977661\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss = 1.3093883991241455 and Validation Accuracy = 0.47540000081062317\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss = 1.2614330053329468 and Validation Accuracy = 0.4943999946117401\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss = 1.250693678855896 and Validation Accuracy = 0.48840001225471497\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss = 1.225188970565796 and Validation Accuracy = 0.4819999933242798\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss = 1.1764546632766724 and Validation Accuracy = 0.5005999803543091\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss = 1.1600896120071411 and Validation Accuracy = 0.5004000067710876\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss = 1.144994854927063 and Validation Accuracy = 0.49720001220703125\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss = 1.1222455501556396 and Validation Accuracy = 0.5070000290870667\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss = 1.1144746541976929 and Validation Accuracy = 0.4986000061035156\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss = 1.0441806316375732 and Validation Accuracy = 0.5116000175476074\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss = 1.0218617916107178 and Validation Accuracy = 0.525600016117096\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss = 0.991119384765625 and Validation Accuracy = 0.5293999910354614\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss = 0.981381893157959 and Validation Accuracy = 0.5275999903678894\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss = 0.9507173299789429 and Validation Accuracy = 0.5368000268936157\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss = 0.9244941473007202 and Validation Accuracy = 0.5315999984741211\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss = 0.9064875245094299 and Validation Accuracy = 0.5234000086784363\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    print (epochs)\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss = 2.800999879837036 and Validation Accuracy = 0.0997999981045723\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss = 2.6728475093841553 and Validation Accuracy = 0.10100000351667404\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss = 2.521149158477783 and Validation Accuracy = 0.10899999737739563\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss = 2.3303167819976807 and Validation Accuracy = 0.15700000524520874\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss = 2.1405866146087646 and Validation Accuracy = 0.20160000026226044\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss = 2.129241466522217 and Validation Accuracy = 0.24240000545978546\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss = 2.0775723457336426 and Validation Accuracy = 0.243599995970726\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss = 2.065932035446167 and Validation Accuracy = 0.2370000034570694\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss = 1.969041109085083 and Validation Accuracy = 0.2809999883174896\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss = 1.8895936012268066 and Validation Accuracy = 0.29679998755455017\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss = 1.9290494918823242 and Validation Accuracy = 0.3269999921321869\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss = 1.8910588026046753 and Validation Accuracy = 0.2948000133037567\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss = 1.7620445489883423 and Validation Accuracy = 0.34380000829696655\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss = 1.7004019021987915 and Validation Accuracy = 0.3386000096797943\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss = 1.7007097005844116 and Validation Accuracy = 0.3668000102043152\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss = 1.7858355045318604 and Validation Accuracy = 0.39500001072883606\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss = 1.7184664011001587 and Validation Accuracy = 0.3790000081062317\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss = 1.630719780921936 and Validation Accuracy = 0.38420000672340393\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss = 1.5702881813049316 and Validation Accuracy = 0.3880000114440918\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss = 1.6163992881774902 and Validation Accuracy = 0.3846000134944916\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss = 1.690342664718628 and Validation Accuracy = 0.4498000144958496\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss = 1.6356921195983887 and Validation Accuracy = 0.42260000109672546\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss = 1.5297634601593018 and Validation Accuracy = 0.40959998965263367\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss = 1.468292474746704 and Validation Accuracy = 0.43320000171661377\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss = 1.51227605342865 and Validation Accuracy = 0.4440000057220459\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss = 1.6285228729248047 and Validation Accuracy = 0.44920000433921814\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss = 1.5330384969711304 and Validation Accuracy = 0.45579999685287476\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss = 1.4464473724365234 and Validation Accuracy = 0.4480000138282776\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss = 1.4057769775390625 and Validation Accuracy = 0.4634000062942505\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss = 1.4221816062927246 and Validation Accuracy = 0.46799999475479126\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss = 1.5497593879699707 and Validation Accuracy = 0.48080000281333923\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss = 1.4612804651260376 and Validation Accuracy = 0.46540001034736633\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss = 1.3862581253051758 and Validation Accuracy = 0.4668000042438507\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss = 1.3543429374694824 and Validation Accuracy = 0.4717999994754791\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss = 1.3978215456008911 and Validation Accuracy = 0.4896000027656555\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss = 1.4814918041229248 and Validation Accuracy = 0.4869999885559082\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss = 1.4329864978790283 and Validation Accuracy = 0.4837999939918518\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss = 1.34114408493042 and Validation Accuracy = 0.49160000681877136\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss = 1.3062652349472046 and Validation Accuracy = 0.4878000020980835\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss = 1.3777767419815063 and Validation Accuracy = 0.4893999993801117\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss = 1.4258549213409424 and Validation Accuracy = 0.4973999857902527\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss = 1.4183303117752075 and Validation Accuracy = 0.4708000123500824\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss = 1.2862972021102905 and Validation Accuracy = 0.4957999885082245\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss = 1.2332817316055298 and Validation Accuracy = 0.5109999775886536\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss = 1.2832918167114258 and Validation Accuracy = 0.5138000249862671\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss = 1.3762571811676025 and Validation Accuracy = 0.5194000005722046\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss = 1.336008906364441 and Validation Accuracy = 0.5044000148773193\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss = 1.241860270500183 and Validation Accuracy = 0.4941999912261963\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss = 1.2253531217575073 and Validation Accuracy = 0.5228000283241272\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss = 1.2489335536956787 and Validation Accuracy = 0.5260000228881836\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss = 1.3719428777694702 and Validation Accuracy = 0.5210000276565552\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss = 1.3308542966842651 and Validation Accuracy = 0.4957999885082245\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss = 1.212643027305603 and Validation Accuracy = 0.4912000000476837\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss = 1.169749140739441 and Validation Accuracy = 0.5311999917030334\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss = 1.2166111469268799 and Validation Accuracy = 0.5249999761581421\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss = 1.3026235103607178 and Validation Accuracy = 0.5314000248908997\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss = 1.273229718208313 and Validation Accuracy = 0.5203999876976013\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss = 1.1317791938781738 and Validation Accuracy = 0.5370000004768372\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss = 1.1299949884414673 and Validation Accuracy = 0.5425999760627747\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss = 1.1754919290542603 and Validation Accuracy = 0.5368000268936157\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss = 1.258999228477478 and Validation Accuracy = 0.5486000180244446\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss = 1.2400182485580444 and Validation Accuracy = 0.5131999850273132\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss = 1.0851918458938599 and Validation Accuracy = 0.5194000005722046\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss = 1.1336407661437988 and Validation Accuracy = 0.548799991607666\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss = 1.1438120603561401 and Validation Accuracy = 0.5486000180244446\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss = 1.247780203819275 and Validation Accuracy = 0.5533999800682068\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss = 1.1859933137893677 and Validation Accuracy = 0.5368000268936157\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss = 1.0821808576583862 and Validation Accuracy = 0.5446000099182129\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss = 1.0706864595413208 and Validation Accuracy = 0.5605999827384949\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss = 1.1124624013900757 and Validation Accuracy = 0.5529999732971191\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss = 1.2018896341323853 and Validation Accuracy = 0.5609999895095825\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss = 1.1411759853363037 and Validation Accuracy = 0.5468000173568726\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss = 1.0488102436065674 and Validation Accuracy = 0.551800012588501\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss = 1.0593830347061157 and Validation Accuracy = 0.5582000017166138\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss = 1.0657153129577637 and Validation Accuracy = 0.5559999942779541\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss = 1.153987169265747 and Validation Accuracy = 0.5753999948501587\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss = 1.089840292930603 and Validation Accuracy = 0.5676000118255615\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss = 1.0430351495742798 and Validation Accuracy = 0.5526000261306763\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss = 1.0464215278625488 and Validation Accuracy = 0.5655999779701233\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss = 1.0401338338851929 and Validation Accuracy = 0.5641999840736389\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss = 1.1315155029296875 and Validation Accuracy = 0.5703999996185303\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss = 1.0603301525115967 and Validation Accuracy = 0.5717999935150146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, CIFAR-10 Batch 3:  Loss = 0.9731886386871338 and Validation Accuracy = 0.5667999982833862\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss = 0.994380533695221 and Validation Accuracy = 0.5809999704360962\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss = 0.9990834593772888 and Validation Accuracy = 0.5690000057220459\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss = 1.0930507183074951 and Validation Accuracy = 0.5825999975204468\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss = 1.0157781839370728 and Validation Accuracy = 0.5789999961853027\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss = 0.9621659517288208 and Validation Accuracy = 0.579800009727478\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss = 0.9559503793716431 and Validation Accuracy = 0.5914000272750854\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss = 0.9867962002754211 and Validation Accuracy = 0.5821999907493591\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss = 1.0825504064559937 and Validation Accuracy = 0.5860000252723694\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss = 1.0312212705612183 and Validation Accuracy = 0.5735999941825867\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss = 0.9636058211326599 and Validation Accuracy = 0.5807999968528748\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss = 0.9485710859298706 and Validation Accuracy = 0.5911999940872192\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss = 0.9729766845703125 and Validation Accuracy = 0.5838000178337097\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss = 1.031743049621582 and Validation Accuracy = 0.6014000177383423\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss = 0.9796493053436279 and Validation Accuracy = 0.5766000151634216\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss = 0.9001217484474182 and Validation Accuracy = 0.5971999764442444\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss = 0.9291017651557922 and Validation Accuracy = 0.605400025844574\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss = 0.9413225054740906 and Validation Accuracy = 0.5842000246047974\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss = 0.9973140358924866 and Validation Accuracy = 0.6055999994277954\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss = 0.9507081508636475 and Validation Accuracy = 0.5968000292778015\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss = 0.8907941579818726 and Validation Accuracy = 0.6047999858856201\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss = 0.9313663840293884 and Validation Accuracy = 0.6061999797821045\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss = 0.9060831665992737 and Validation Accuracy = 0.5979999899864197\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss = 0.9798767566680908 and Validation Accuracy = 0.6021999716758728\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss = 0.9485613703727722 and Validation Accuracy = 0.5860000252723694\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss = 0.8772729635238647 and Validation Accuracy = 0.5971999764442444\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss = 0.8939932584762573 and Validation Accuracy = 0.6025999784469604\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss = 0.9157071709632874 and Validation Accuracy = 0.5974000096321106\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss = 0.9750726222991943 and Validation Accuracy = 0.6055999994277954\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss = 0.9364960193634033 and Validation Accuracy = 0.6014000177383423\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss = 0.8673727512359619 and Validation Accuracy = 0.5983999967575073\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss = 0.8601030111312866 and Validation Accuracy = 0.6169999837875366\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss = 0.8983466625213623 and Validation Accuracy = 0.5929999947547913\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss = 0.9355779886245728 and Validation Accuracy = 0.6140000224113464\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss = 0.8825652599334717 and Validation Accuracy = 0.6014000177383423\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss = 0.8517388701438904 and Validation Accuracy = 0.6069999933242798\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss = 0.8232347965240479 and Validation Accuracy = 0.6168000102043152\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss = 0.8663997054100037 and Validation Accuracy = 0.6029999852180481\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss = 0.9282224774360657 and Validation Accuracy = 0.6111999750137329\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss = 0.8958938121795654 and Validation Accuracy = 0.6123999953269958\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss = 0.7971311807632446 and Validation Accuracy = 0.6144000291824341\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss = 0.8236284852027893 and Validation Accuracy = 0.6179999709129333\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss = 0.8426036238670349 and Validation Accuracy = 0.6177999973297119\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss = 0.8533464670181274 and Validation Accuracy = 0.6258000135421753\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss = 0.8618022799491882 and Validation Accuracy = 0.6186000108718872\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss = 0.7577717900276184 and Validation Accuracy = 0.6161999702453613\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss = 0.788221001625061 and Validation Accuracy = 0.621399998664856\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss = 0.8421543836593628 and Validation Accuracy = 0.6087999939918518\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss = 0.8730340003967285 and Validation Accuracy = 0.620199978351593\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss = 0.8298958539962769 and Validation Accuracy = 0.616599977016449\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss = 0.7764936685562134 and Validation Accuracy = 0.6161999702453613\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss = 0.7719091773033142 and Validation Accuracy = 0.6190000176429749\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss = 0.8042386770248413 and Validation Accuracy = 0.6164000034332275\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss = 0.8555810451507568 and Validation Accuracy = 0.6215999722480774\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss = 0.8274146318435669 and Validation Accuracy = 0.6137999892234802\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss = 0.7615144848823547 and Validation Accuracy = 0.6237999796867371\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss = 0.7769222259521484 and Validation Accuracy = 0.6277999877929688\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss = 0.7874867916107178 and Validation Accuracy = 0.6177999973297119\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss = 0.8607261776924133 and Validation Accuracy = 0.6248000264167786\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss = 0.8048633933067322 and Validation Accuracy = 0.6144000291824341\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss = 0.7637938261032104 and Validation Accuracy = 0.61080002784729\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss = 0.7386444807052612 and Validation Accuracy = 0.6276000142097473\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss = 0.776685893535614 and Validation Accuracy = 0.6226000189781189\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss = 0.8408816456794739 and Validation Accuracy = 0.6248000264167786\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss = 0.7952011227607727 and Validation Accuracy = 0.6227999925613403\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss = 0.733124852180481 and Validation Accuracy = 0.6262000203132629\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss = 0.732571005821228 and Validation Accuracy = 0.6255999803543091\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss = 0.7576985955238342 and Validation Accuracy = 0.623199999332428\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss = 0.8155630826950073 and Validation Accuracy = 0.6362000107765198\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss = 0.779087245464325 and Validation Accuracy = 0.6269999742507935\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss = 0.6990640163421631 and Validation Accuracy = 0.6281999945640564\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss = 0.6989326477050781 and Validation Accuracy = 0.635200023651123\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss = 0.7406541109085083 and Validation Accuracy = 0.629800021648407\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss = 0.7673524618148804 and Validation Accuracy = 0.6291999816894531\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss = 0.7542313933372498 and Validation Accuracy = 0.6417999863624573\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss = 0.6821193099021912 and Validation Accuracy = 0.6320000290870667\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss = 0.7011252641677856 and Validation Accuracy = 0.6294000148773193\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss = 0.6893466711044312 and Validation Accuracy = 0.628600001335144\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss = 0.7569695711135864 and Validation Accuracy = 0.6367999911308289\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss = 0.7428659796714783 and Validation Accuracy = 0.6353999972343445\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss = 0.6949491500854492 and Validation Accuracy = 0.621999979019165\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss = 0.6816523671150208 and Validation Accuracy = 0.633400022983551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, CIFAR-10 Batch 5:  Loss = 0.7251812219619751 and Validation Accuracy = 0.6349999904632568\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss = 0.7294492721557617 and Validation Accuracy = 0.6434000134468079\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss = 0.7231690883636475 and Validation Accuracy = 0.6276000142097473\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss = 0.6575773358345032 and Validation Accuracy = 0.6320000290870667\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss = 0.6646420359611511 and Validation Accuracy = 0.6359999775886536\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss = 0.7029480934143066 and Validation Accuracy = 0.6290000081062317\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss = 0.7120507955551147 and Validation Accuracy = 0.6381999850273132\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss = 0.7029290199279785 and Validation Accuracy = 0.6371999979019165\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss = 0.6505929827690125 and Validation Accuracy = 0.6322000026702881\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss = 0.6539695262908936 and Validation Accuracy = 0.6377999782562256\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss = 0.6593542098999023 and Validation Accuracy = 0.6376000046730042\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss = 0.698373556137085 and Validation Accuracy = 0.6363999843597412\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss = 0.7014596462249756 and Validation Accuracy = 0.6273999810218811\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss = 0.6415884494781494 and Validation Accuracy = 0.640999972820282\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss = 0.6853250861167908 and Validation Accuracy = 0.628600001335144\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss = 0.6594274640083313 and Validation Accuracy = 0.6413999795913696\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss = 0.668901264667511 and Validation Accuracy = 0.6388000249862671\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss = 0.6962021589279175 and Validation Accuracy = 0.6407999992370605\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss = 0.6353329420089722 and Validation Accuracy = 0.642799973487854\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss = 0.6417596936225891 and Validation Accuracy = 0.6330000162124634\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss = 0.641300618648529 and Validation Accuracy = 0.6394000053405762\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss = 0.6399326324462891 and Validation Accuracy = 0.6388000249862671\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss = 0.6574796438217163 and Validation Accuracy = 0.6417999863624573\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss = 0.5953131914138794 and Validation Accuracy = 0.6395999789237976\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss = 0.6186832785606384 and Validation Accuracy = 0.6424000263214111\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss = 0.6102243661880493 and Validation Accuracy = 0.6381999850273132\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss = 0.6626309752464294 and Validation Accuracy = 0.6413999795913696\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss = 0.6500905752182007 and Validation Accuracy = 0.6438000202178955\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss = 0.612647533416748 and Validation Accuracy = 0.6366000175476074\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss = 0.6304300427436829 and Validation Accuracy = 0.6308000087738037\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss = 0.648777425289154 and Validation Accuracy = 0.6416000127792358\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss = 0.6572256088256836 and Validation Accuracy = 0.6407999992370605\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss = 0.6459275484085083 and Validation Accuracy = 0.6521999835968018\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss = 0.588822066783905 and Validation Accuracy = 0.6430000066757202\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss = 0.5807976722717285 and Validation Accuracy = 0.6395999789237976\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss = 0.6159249544143677 and Validation Accuracy = 0.646399974822998\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss = 0.6484395265579224 and Validation Accuracy = 0.645799994468689\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss = 0.6206094026565552 and Validation Accuracy = 0.6498000025749207\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss = 0.593422532081604 and Validation Accuracy = 0.6388000249862671\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss = 0.5874971747398376 and Validation Accuracy = 0.6417999863624573\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss = 0.5936239957809448 and Validation Accuracy = 0.650600016117096\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss = 0.6152704358100891 and Validation Accuracy = 0.646399974822998\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss = 0.6181066632270813 and Validation Accuracy = 0.6507999897003174\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss = 0.5908918380737305 and Validation Accuracy = 0.6403999924659729\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss = 0.5552011728286743 and Validation Accuracy = 0.6467999815940857\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss = 0.5837681889533997 and Validation Accuracy = 0.6478000283241272\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss = 0.6208240985870361 and Validation Accuracy = 0.6452000141143799\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss = 0.6361974477767944 and Validation Accuracy = 0.6484000086784363\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss = 0.564063549041748 and Validation Accuracy = 0.6439999938011169\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss = 0.5458097457885742 and Validation Accuracy = 0.6413999795913696\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss = 0.5841844081878662 and Validation Accuracy = 0.6453999876976013\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss = 0.6043950319290161 and Validation Accuracy = 0.6525999903678894\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss = 0.5964829921722412 and Validation Accuracy = 0.6516000032424927\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss = 0.5564060211181641 and Validation Accuracy = 0.6442000269889832\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss = 0.5387495756149292 and Validation Accuracy = 0.6406000256538391\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss = 0.565437912940979 and Validation Accuracy = 0.6413999795913696\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss = 0.5987561941146851 and Validation Accuracy = 0.651199996471405\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss = 0.5813735127449036 and Validation Accuracy = 0.6516000032424927\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss = 0.5320531725883484 and Validation Accuracy = 0.6492000222206116\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss = 0.4991263449192047 and Validation Accuracy = 0.6516000032424927\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss = 0.5656506419181824 and Validation Accuracy = 0.6399999856948853\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.6419979333877563\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11917ada0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
